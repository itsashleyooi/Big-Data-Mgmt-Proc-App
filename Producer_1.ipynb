{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIT3182: Assignment 2 Part B (Event Producer 1) \n",
    "\n",
    "### Name: Ashley Ooi Yan-Lin (ID: 31171095)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Processing Data Stream\n",
    "\n",
    "### (a) Write a python program that loads all the data from climate_streaming.csv and randomly (with replacement) feed the data to the stream every 10 seconds. You will need to append additional information such as producer information to identify the producer and created date. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to establish a connection with our MongoClient and retrieve the collection created in Part A to obtain the most recent date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "client = MongoClient () \n",
    "db = client.fit3182_assignment_db\n",
    "collection = db.partA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to develop our program to enable the transmission of our data to Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 159.0,\n",
      "   \"air_temperature_celcius\": 17.0,\n",
      "   \"created_date\": \"2022-01-01\",\n",
      "   \"flag_precipitation\": \"I\",\n",
      "   \"latitude\": -35.2881,\n",
      "   \"longitude\": 142.5679,\n",
      "   \"max_wind_speed\": 22.9,\n",
      "   \"precipitation\": 0.0,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 38.7,\n",
      "   \"windspeed_knots\": 16.8\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 113.0,\n",
      "   \"air_temperature_celcius\": 13.0,\n",
      "   \"created_date\": \"2022-01-02\",\n",
      "   \"flag_precipitation\": \"G\",\n",
      "   \"latitude\": -37.459,\n",
      "   \"longitude\": 148.092,\n",
      "   \"max_wind_speed\": 15.9,\n",
      "   \"precipitation\": 0.0,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 48.5,\n",
      "   \"windspeed_knots\": 7.1\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 150.0,\n",
      "   \"air_temperature_celcius\": 18.0,\n",
      "   \"created_date\": \"2022-01-03\",\n",
      "   \"flag_precipitation\": \"G\",\n",
      "   \"latitude\": -36.575,\n",
      "   \"longitude\": 146.6668,\n",
      "   \"max_wind_speed\": 15.9,\n",
      "   \"precipitation\": 0.0,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 53.6,\n",
      "   \"windspeed_knots\": 7.9\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 195.0,\n",
      "   \"air_temperature_celcius\": 25.0,\n",
      "   \"created_date\": \"2022-01-04\",\n",
      "   \"flag_precipitation\": \"I\",\n",
      "   \"latitude\": -36.404,\n",
      "   \"longitude\": 142.5467,\n",
      "   \"max_wind_speed\": 8.9,\n",
      "   \"precipitation\": 0.0,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 60.9,\n",
      "   \"windspeed_knots\": 6.3\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 133.0,\n",
      "   \"air_temperature_celcius\": 16.0,\n",
      "   \"created_date\": \"2022-01-05\",\n",
      "   \"flag_precipitation\": \"G\",\n",
      "   \"latitude\": -37.95,\n",
      "   \"longitude\": 142.366,\n",
      "   \"max_wind_speed\": 15.0,\n",
      "   \"precipitation\": 0.0,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 53.6,\n",
      "   \"windspeed_knots\": 8.1\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 74.0,\n",
      "   \"air_temperature_celcius\": 8.0,\n",
      "   \"created_date\": \"2022-01-06\",\n",
      "   \"flag_precipitation\": \"G\",\n",
      "   \"latitude\": -37.335,\n",
      "   \"longitude\": 148.064,\n",
      "   \"max_wind_speed\": 16.9,\n",
      "   \"precipitation\": 0.47,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 41.0,\n",
      "   \"windspeed_knots\": 11.0\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 167.0,\n",
      "   \"air_temperature_celcius\": 20.0,\n",
      "   \"created_date\": \"2022-01-07\",\n",
      "   \"flag_precipitation\": \"I\",\n",
      "   \"latitude\": -37.861999999999995,\n",
      "   \"longitude\": 144.175,\n",
      "   \"max_wind_speed\": 21.0,\n",
      "   \"precipitation\": 0.0,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 52.9,\n",
      "   \"windspeed_knots\": 17.0\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 75.0,\n",
      "   \"air_temperature_celcius\": 8.0,\n",
      "   \"created_date\": \"2022-01-08\",\n",
      "   \"flag_precipitation\": \"G\",\n",
      "   \"latitude\": -37.332,\n",
      "   \"longitude\": 148.091,\n",
      "   \"max_wind_speed\": 14.0,\n",
      "   \"precipitation\": 0.0,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 39.3,\n",
      "   \"windspeed_knots\": 7.7\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 173.0,\n",
      "   \"air_temperature_celcius\": 21.0,\n",
      "   \"created_date\": \"2022-01-09\",\n",
      "   \"flag_precipitation\": \"I\",\n",
      "   \"latitude\": -37.946,\n",
      "   \"longitude\": 144.342,\n",
      "   \"max_wind_speed\": 16.9,\n",
      "   \"precipitation\": 0.0,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 54.9,\n",
      "   \"windspeed_knots\": 7.4\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 139.0,\n",
      "   \"air_temperature_celcius\": 16.0,\n",
      "   \"created_date\": \"2022-01-10\",\n",
      "   \"flag_precipitation\": \"G\",\n",
      "   \"latitude\": -37.6,\n",
      "   \"longitude\": 149.325,\n",
      "   \"max_wind_speed\": 12.0,\n",
      "   \"precipitation\": 0.0,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 48.1,\n",
      "   \"windspeed_knots\": 9.3\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 133.0,\n",
      "   \"air_temperature_celcius\": 16.0,\n",
      "   \"created_date\": \"2022-01-11\",\n",
      "   \"flag_precipitation\": \"G\",\n",
      "   \"latitude\": -37.603,\n",
      "   \"longitude\": 149.32399999999998,\n",
      "   \"max_wind_speed\": 16.9,\n",
      "   \"precipitation\": 0.16,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 53.6,\n",
      "   \"windspeed_knots\": 12.1\n",
      "}\n",
      "Message published successfully. {\n",
      "   \"GHI_w/m2\": 102.0,\n",
      "   \"air_temperature_celcius\": 11.0,\n",
      "   \"created_date\": \"2022-01-12\",\n",
      "   \"flag_precipitation\": \"G\",\n",
      "   \"latitude\": -36.7179,\n",
      "   \"longitude\": 142.2536,\n",
      "   \"max_wind_speed\": 15.0,\n",
      "   \"precipitation\": 0.04,\n",
      "   \"producer_id\": \"climate_producer\",\n",
      "   \"relative_humidity\": 40.4,\n",
      "   \"windspeed_knots\": 9.2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# importing statements\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "import random\n",
    "\n",
    "# Reads data from climate_streaming.csv, puts each row data into a document and appends all such documents into a list.\n",
    "def read_climate_streaming():\n",
    "    climate_streaming = pd.read_csv('climate_streaming.csv')\n",
    "    climate_streaming.rename(columns = {'precipitation ':'precipitation'}, inplace = True)\n",
    "    climate_streaming['precipitation_flag'] = climate_streaming['precipitation'].str[-1]\n",
    "    climate_streaming['precipitation'] = climate_streaming['precipitation'].str[0:-1]\n",
    "    \n",
    "    data = []\n",
    "    for index,climateRow in climate_streaming.iterrows():\n",
    "        document = {}\n",
    "        document['latitude'] = float(climateRow['latitude'])\n",
    "        document['longitude'] = float(climateRow['longitude'])\n",
    "        document['air_temperature_celcius'] = int(climateRow['air_temperature_celcius'])\n",
    "        document['relative_humidity'] = float(climateRow['relative_humidity'])\n",
    "        document['windspeed_knots'] = float(climateRow['windspeed_knots'])\n",
    "        document['max_wind_speed'] = float(climateRow['max_wind_speed'])\n",
    "        document['precipitation'] = float(climateRow['precipitation'].strip()) #Remove any leading and trailing spaces for precipitation data\n",
    "        document['precipitation_flag'] = climateRow['precipitation_flag'].strip()\n",
    "        document['GHI_w/m2'] = int(climateRow['GHI_w/m2'])\n",
    "        data.append(document)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Gets the latest date in our collection\n",
    "def get_latest_date():\n",
    "    latest_date = collection.aggregate([\n",
    "                {\"$sort\":{\"date\":-1}},\n",
    "                {\"$project\":{\"_id\":0,\"date\":1}},\n",
    "                {\"$limit\":1}\n",
    "                ])\n",
    "    for document in latest_date:\n",
    "        latest_date = document['date']\n",
    "    return latest_date\n",
    "    \n",
    "\n",
    "# Publishes message to Kafka\n",
    "def publish_message(producer_instance, topic_name, data):\n",
    "    try:\n",
    "        producer_instance.send(topic_name, value=data)\n",
    "        print('Message published successfully. Data: ' + str(data))\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))\n",
    "        \n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                                  value_serializer=lambda x: dumps(x).encode('ascii'),\n",
    "                                  api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    topic = 'PartB'\n",
    "    print('Publishing records..')\n",
    "    producer01 = connect_kafka_producer()\n",
    "    data = read_climate_streaming() # Gets all the documents produced from climate_streaming.csv\n",
    "    latest_date = get_latest_date() + timedelta(days=1) # After getting latest date, we would add one day to it to get the first date we would use to start feeding data\n",
    "    daysPassed = 0  # Tracks how many days we should add to our latest date \n",
    "\n",
    "    while True:\n",
    "        chosenData = random.choice(data) # Randomly chooses a document from our list of documents\n",
    "        curr_date = latest_date + timedelta(days=daysPassed) # Creates the date we will use to feed our data by adding the number of days passed to our latest date from Part A\n",
    "        chosenData['producer'] = \"climate_streaming\" \n",
    "        chosenData[\"created_date\"] = curr_date.strftime(\"%d/%m/%Y\")\n",
    "        publish_message(producer01, topic, chosenData)\n",
    "        daysPassed += 1 # After we insert a climate streaming data, add 1 day to daysPassed so the next date we would use to feed our data would be incremented by 1 day\n",
    "        sleep(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
